{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_csv(r\"D:\\reconheceprodutos\\produtos_vpj.csv\",sep=\";\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de classificação para descricao_grupo_custo:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "             BOVINOS - ANGUS       0.94      0.96      0.95       106\n",
      "              BOVINOS - ZEBU       0.89      1.00      0.94        24\n",
      "INDUSTRIALIZADOS - BOV ANGUS       0.00      0.00      0.00         5\n",
      " INDUSTRIALIZADOS - BOV ZEBU       0.00      0.00      0.00         1\n",
      "    INDUSTRIALIZADOS - SUÍNO       1.00      0.11      0.20         9\n",
      "                      OVINOS       1.00      1.00      1.00        27\n",
      "                     REVENDA       1.00      1.00      1.00        21\n",
      "              SUÍNOS - DUROC       0.80      0.97      0.88        33\n",
      "             SUÍNOS - LEITOA       1.00      1.00      1.00         1\n",
      "            SUÍNOS - MARROTE       1.00      1.00      1.00         2\n",
      "\n",
      "                    accuracy                           0.92       229\n",
      "                   macro avg       0.76      0.70      0.70       229\n",
      "                weighted avg       0.91      0.92      0.90       229\n",
      "\n",
      "\n",
      "Relatório de classificação para descricao_subgrupo_custo:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                    ACÉM       1.00      1.00      1.00         7\n",
      "                 ALCATRA       1.00      0.88      0.93         8\n",
      "                 BARRIGA       1.00      1.00      1.00         4\n",
      "            CAPA DE FILÉ       0.50      1.00      0.67         1\n",
      "             CARNE ANGUS       0.00      0.00      0.00         1\n",
      "              CONTRAFILÉ       1.00      0.75      0.86         8\n",
      "CONTRAFILÉ E FILÉ MIGNON       1.00      0.25      0.40         4\n",
      "                 COSTELA       0.97      0.91      0.94        34\n",
      "       COSTELA DIANTEIRO       0.33      1.00      0.50         1\n",
      "          COSTELA JANELA       0.67      0.67      0.67         3\n",
      "           COSTELA MINGA       1.00      1.00      1.00         2\n",
      "              COXÃO BOLA       1.00      0.50      0.67         2\n",
      "              COXÃO DURO       1.00      0.80      0.89         5\n",
      "              COXÃO MOLE       1.00      1.00      1.00         6\n",
      "                   CUPIM       0.50      1.00      0.67         1\n",
      "         FILÉ DE COSTELA       0.95      0.95      0.95        19\n",
      "             FILÉ MIGNON       0.80      0.67      0.73         6\n",
      "               FRALDINHA       0.57      1.00      0.73         4\n",
      "              HAMBURGUER       0.92      1.00      0.96        24\n",
      "              INDUSTRIAL       0.62      0.83      0.71         6\n",
      "                  JOELHO       1.00      1.00      1.00         2\n",
      "                  LEITOA       1.00      1.00      1.00         1\n",
      "               LINGUIÇAS       0.96      1.00      0.98        23\n",
      "                   LOMBO       0.00      0.00      0.00         0\n",
      "      MAMINHA DA ALCATRA       1.00      1.00      1.00         3\n",
      "                   MISTO       0.00      0.00      0.00         1\n",
      "                 MÚSCULO       1.00      1.00      1.00         4\n",
      "                  OUTROS       0.00      0.00      0.00         0\n",
      "                  PALETA       0.83      0.83      0.83         6\n",
      "                 PATINHO       1.00      1.00      1.00         4\n",
      "                   PEITO       1.00      1.00      1.00         3\n",
      "                PEIXINHO       1.00      1.00      1.00         1\n",
      "             PELE LOMBAR       0.00      0.00      0.00         1\n",
      "                  PERNIL       1.00      0.67      0.80         3\n",
      "                 PICANHA       1.00      1.00      1.00         8\n",
      "                    RABO       1.00      1.00      1.00         1\n",
      "  REVENDA - DISTRIBUIÇÃO       0.92      1.00      0.96        11\n",
      "          REVENDA - SAIS       1.00      1.00      1.00         5\n",
      "      REVENDA - SOUVENIR       0.00      0.00      0.00         1\n",
      "  REVENDA - SWEET VALLEY       1.00      1.00      1.00         4\n",
      "                  TUTANO       0.00      0.00      0.00         1\n",
      "\n",
      "                accuracy                           0.90       229\n",
      "               macro avg       0.74      0.75      0.73       229\n",
      "            weighted avg       0.91      0.90      0.90       229\n",
      "\n",
      "[['SUÍNOS - DUROC', 'LINGUIÇAS']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\reconheceprodutos\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "dados = pd.read_csv(r\"D:\\reconheceprodutos\\produtos_vpj.csv\", sep=\";\", encoding='latin-1')\n",
    "\n",
    "\n",
    "dados['item_descricao'] = dados['item_descricao'].str.lower()\n",
    "\n",
    "\n",
    "def aplicar_regras_manuais(descricao):\n",
    "    descricao = descricao.lower()\n",
    "    if \"bacon\" in descricao or \"linguiça\" in descricao:\n",
    "        grupo = \"SUÍNOS - DUROC\"\n",
    "        subgrupo = \"LINGUIÇAS\"\n",
    "    elif \"cordeiro\" in descricao:\n",
    "        grupo = \"OVINOS\"\n",
    "        subgrupo = \"COSTELA\"\n",
    "    else:\n",
    "        grupo, subgrupo = None, None\n",
    "    return grupo, subgrupo\n",
    "\n",
    "\n",
    "dados['grupo_regra'], dados['subgrupo_regra'] = zip(*dados['item_descricao'].apply(aplicar_regras_manuais))\n",
    "\n",
    "\n",
    "X = dados['item_descricao']\n",
    "y_grupo = dados['descricao_grupo_custo'].where(dados['grupo_regra'].isnull(), dados['grupo_regra'])\n",
    "y_subgrupo = dados['descricao_subgrupo_custo'].where(dados['subgrupo_regra'].isnull(), dados['subgrupo_regra'])\n",
    "y = pd.DataFrame({'descricao_grupo_custo': y_grupo, 'descricao_subgrupo_custo': y_subgrupo})\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_grupo = [pred[0] for pred in y_pred]\n",
    "y_pred_subgrupo = [pred[1] for pred in y_pred]\n",
    "\n",
    "\n",
    "print(\"Relatório de classificação para descricao_grupo_custo:\")\n",
    "print(classification_report(y_test['descricao_grupo_custo'], y_pred_grupo))\n",
    "\n",
    "print(\"\\nRelatório de classificação para descricao_subgrupo_custo:\")\n",
    "print(classification_report(y_test['descricao_subgrupo_custo'], y_pred_subgrupo))\n",
    "\n",
    "\n",
    "def predizer_grupo_subgrupo(descricao_item):\n",
    "    descricao_item = descricao_item.lower()\n",
    "    grupo_regra, subgrupo_regra = aplicar_regras_manuais(descricao_item)\n",
    "    \n",
    "    \n",
    "    if grupo_regra and subgrupo_regra:\n",
    "        return [[grupo_regra, subgrupo_regra]]\n",
    "    \n",
    "    return pipeline.predict([descricao_item])\n",
    "\n",
    "\n",
    "descricao_exemplo = \"LINGUICA BACON 500G - CX\"\n",
    "print(predizer_grupo_subgrupo(descricao_exemplo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SUÍNOS - DUROC', 'LINGUIÇAS']]\n"
     ]
    }
   ],
   "source": [
    "print(predizer_grupo_subgrupo(descricao_exemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos e encoders carregados dos arquivos .pkl.\n",
      "\n",
      "Predição para a descrição do item:\n",
      "[['DOCE DE COCO CORTE 700G CX 15 UN - SWEET VALLEY', 'REVENDA', 'REVENDA - SWEET VALLEY']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "model_grupo_path = 'classifier_grupo_final.pkl'\n",
    "model_subgrupo_path = 'classifier_subgrupo_final.pkl'\n",
    "le_grupo_path = 'le_grupo.pkl'\n",
    "le_subgrupo_path = 'le_subgrupo.pkl'\n",
    "le_marca_path = 'le_marca.pkl'\n",
    "tfidf_vectorizer_path = 'tfidf_vectorizer.pkl'\n",
    "onehot_encoder_path = 'onehot_encoder.pkl'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "\n",
    "def extrair_marca(texto):\n",
    "    texto = texto.lower()\n",
    "    if '-' in texto:\n",
    "        return texto.split('-')[-1].strip()\n",
    "    else:\n",
    "        return 'desconhecido'\n",
    "\n",
    "\n",
    "def extrair_palavras_chave(texto):\n",
    "    palavras_irrelevantes = set(['cx', 'un', 'g', 'kg', 'ml', 'l', 'mg'])\n",
    "    palavras = texto.lower().split()\n",
    "    palavras_filtradas = [palavra for palavra in palavras if palavra not in palavras_irrelevantes and not palavra.isdigit()]\n",
    "    return ' '.join(palavras_filtradas)\n",
    "\n",
    "\n",
    "def gerar_embeddings(textos):\n",
    "    embeddings = []\n",
    "    batch_size = 16 \n",
    "    for i in range(0, len(textos), batch_size):\n",
    "        batch_textos = textos.iloc[i:i+batch_size].tolist()\n",
    "        inputs = tokenizer(batch_textos, return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "if (os.path.exists(model_grupo_path) and os.path.exists(model_subgrupo_path) and\n",
    "    os.path.exists(le_grupo_path) and os.path.exists(le_subgrupo_path) and\n",
    "    os.path.exists(le_marca_path) and os.path.exists(tfidf_vectorizer_path) and\n",
    "    os.path.exists(onehot_encoder_path)):\n",
    "    \n",
    "    classifier_grupo_final = joblib.load(model_grupo_path)\n",
    "    classifier_subgrupo_final = joblib.load(model_subgrupo_path)\n",
    "    le_grupo = joblib.load(le_grupo_path)\n",
    "    le_subgrupo = joblib.load(le_subgrupo_path)\n",
    "    le_marca = joblib.load(le_marca_path)\n",
    "    tfidf_vectorizer = joblib.load(tfidf_vectorizer_path)\n",
    "    onehot_encoder = joblib.load(onehot_encoder_path)\n",
    "    print(\"Modelos e encoders carregados dos arquivos .pkl.\")\n",
    "else:\n",
    "    \n",
    "    dados = pd.read_csv(r\"D:\\reconheceprodutos\\produtos_vpj.csv\", sep=\";\", encoding='latin-1')\n",
    "\n",
    "    \n",
    "    dados['item_descricao'] = dados['item_descricao'].str.lower().str.strip()\n",
    "    dados['marca'] = dados['item_descricao'].apply(extrair_marca)\n",
    "    dados['palavras_chave'] = dados['item_descricao'].apply(extrair_palavras_chave)\n",
    "\n",
    "    \n",
    "    X_texto = dados['palavras_chave']\n",
    "    X_marca = dados['marca']\n",
    "    y = dados[['descricao_grupo_custo', 'descricao_subgrupo_custo']]\n",
    "\n",
    "    \n",
    "    le_grupo = LabelEncoder()\n",
    "    le_subgrupo = LabelEncoder()\n",
    "    le_marca = LabelEncoder()\n",
    "\n",
    "    y['descricao_grupo_custo'] = le_grupo.fit_transform(y['descricao_grupo_custo'])\n",
    "    y['descricao_subgrupo_custo'] = le_subgrupo.fit_transform(y['descricao_subgrupo_custo'])\n",
    "    X_marca_encoded = le_marca.fit_transform(X_marca)\n",
    "\n",
    "    \n",
    "    y_combined = y['descricao_grupo_custo'].astype(str) + \"_\" + y['descricao_subgrupo_custo'].astype(str)\n",
    "\n",
    "    \n",
    "    print(\"Gerando embeddings, isso pode levar algum tempo...\")\n",
    "    X_embeddings = gerar_embeddings(X_texto)\n",
    "\n",
    "   \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(X_texto).toarray()\n",
    "\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    X_marca_onehot = onehot_encoder.fit_transform(X_marca.values.reshape(-1, 1))\n",
    "\n",
    "    \n",
    "    X_final = np.hstack((X_embeddings, X_tfidf, X_marca_onehot))\n",
    "\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    reportes_grupo = []\n",
    "    reportes_subgrupo = []\n",
    "\n",
    "   \n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X_final, y_combined)):\n",
    "        print(f\"\\nIniciando fold {fold + 1}...\")\n",
    "        \n",
    "        X_train, X_test = X_final[train_index], X_final[test_index]\n",
    "        y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
    "\n",
    "        \n",
    "        classifier_grupo = RandomForestClassifier(random_state=42, n_estimators=500, max_depth=None)\n",
    "        classifier_grupo.fit(X_train, y_train['descricao_grupo_custo'])\n",
    "\n",
    "        \n",
    "        classifier_subgrupo = RandomForestClassifier(random_state=42, n_estimators=500, max_depth=None)\n",
    "        classifier_subgrupo.fit(X_train, y_train['descricao_subgrupo_custo'])\n",
    "\n",
    "        \n",
    "        y_pred_grupo = classifier_grupo.predict(X_test)\n",
    "        y_pred_subgrupo = classifier_subgrupo.predict(X_test)\n",
    "\n",
    "        \n",
    "        y_test['descricao_grupo_custo'] = le_grupo.inverse_transform(y_test['descricao_grupo_custo'])\n",
    "        y_test['descricao_subgrupo_custo'] = le_subgrupo.inverse_transform(y_test['descricao_subgrupo_custo'])\n",
    "        y_pred_grupo_decoded = le_grupo.inverse_transform(y_pred_grupo)\n",
    "        y_pred_subgrupo_decoded = le_subgrupo.inverse_transform(y_pred_subgrupo)\n",
    "\n",
    "        \n",
    "        print(\"\\nRelatório de classificação para descricao_grupo_custo nesta divisão:\")\n",
    "        report_grupo = classification_report(y_test['descricao_grupo_custo'], y_pred_grupo_decoded, output_dict=True)\n",
    "        reportes_grupo.append(report_grupo)\n",
    "        print(classification_report(y_test['descricao_grupo_custo'], y_pred_grupo_decoded))\n",
    "\n",
    "        print(\"\\nRelatório de classificação para descricao_subgrupo_custo nesta divisão:\")\n",
    "        report_subgrupo = classification_report(y_test['descricao_subgrupo_custo'], y_pred_subgrupo_decoded, output_dict=True)\n",
    "        reportes_subgrupo.append(report_subgrupo)\n",
    "        print(classification_report(y_test['descricao_subgrupo_custo'], y_pred_subgrupo_decoded))\n",
    "\n",
    "    \n",
    "    def calcular_media_relatorios(reports):\n",
    "        \n",
    "        metrics = {}\n",
    "        num_reports = len(reports)\n",
    "        for report in reports:\n",
    "            for label in report:\n",
    "                if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                    if label not in metrics:\n",
    "                        metrics[label] = {'precision': report[label]['precision'],\n",
    "                                          'recall': report[label]['recall'],\n",
    "                                          'f1-score': report[label]['f1-score'],\n",
    "                                          'support': report[label]['support']}\n",
    "                    else:\n",
    "                        metrics[label]['precision'] += report[label]['precision']\n",
    "                        metrics[label]['recall'] += report[label]['recall']\n",
    "                        metrics[label]['f1-score'] += report[label]['f1-score']\n",
    "                        metrics[label]['support'] += report[label]['support']\n",
    "        \n",
    "        for label in metrics:\n",
    "            metrics[label]['precision'] /= num_reports\n",
    "            metrics[label]['recall'] /= num_reports\n",
    "            metrics[label]['f1-score'] /= num_reports\n",
    "        return metrics\n",
    "\n",
    "   \n",
    "    print(\"\\nMédia das métricas para descricao_grupo_custo após K-Fold:\")\n",
    "    media_grupo = calcular_media_relatorios(reportes_grupo)\n",
    "    print(media_grupo)\n",
    "\n",
    "    print(\"\\nMédia das métricas para descricao_subgrupo_custo após K-Fold:\")\n",
    "    media_subgrupo = calcular_media_relatorios(reportes_subgrupo)\n",
    "    print(media_subgrupo)\n",
    "\n",
    "    \n",
    "    print(\"\\nTreinando o modelo final em todo o conjunto de dados...\")\n",
    "    \n",
    "    classifier_grupo_final = RandomForestClassifier(random_state=42, n_estimators=500, max_depth=None)\n",
    "    classifier_grupo_final.fit(X_final, y['descricao_grupo_custo'])\n",
    "\n",
    "   \n",
    "    classifier_subgrupo_final = RandomForestClassifier(random_state=42, n_estimators=500, max_depth=None)\n",
    "    classifier_subgrupo_final.fit(X_final, y['descricao_subgrupo_custo'])\n",
    "\n",
    "   \n",
    "    joblib.dump(classifier_grupo_final, model_grupo_path)\n",
    "    joblib.dump(classifier_subgrupo_final, model_subgrupo_path)\n",
    "    joblib.dump(le_grupo, le_grupo_path)\n",
    "    joblib.dump(le_subgrupo, le_subgrupo_path)\n",
    "    joblib.dump(le_marca, le_marca_path)\n",
    "    joblib.dump(tfidf_vectorizer, tfidf_vectorizer_path)\n",
    "    joblib.dump(onehot_encoder, onehot_encoder_path)\n",
    "    print(\"Modelos e encoders salvos em arquivos .pkl.\")\n",
    "\n",
    "\n",
    "def predizer_grupo_subgrupo(descricao_item):\n",
    "    descricao_item_original = descricao_item \n",
    "    descricao_item = descricao_item.lower().strip()\n",
    "    marca = extrair_marca(descricao_item)\n",
    "    palavras_chave = extrair_palavras_chave(descricao_item)\n",
    "\n",
    "    \n",
    "    inputs = tokenizer([palavras_chave], return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    \n",
    "    tfidf_vector = tfidf_vectorizer.transform([palavras_chave]).toarray()\n",
    "\n",
    "    \n",
    "    if marca in onehot_encoder.categories_[0]:\n",
    "        marca_encoded = onehot_encoder.transform([[marca]])\n",
    "    else:\n",
    "        marca_encoded = np.zeros((1, len(onehot_encoder.categories_[0])))\n",
    "\n",
    "  \n",
    "    embedding_final = np.hstack((embedding, tfidf_vector, marca_encoded))\n",
    "\n",
    "  \n",
    "    pred_grupo = classifier_grupo_final.predict(embedding_final)\n",
    "    pred_subgrupo = classifier_subgrupo_final.predict(embedding_final)\n",
    "\n",
    "    \n",
    "    proba_subgrupo = classifier_subgrupo_final.predict_proba(embedding_final)\n",
    "    max_proba_subgrupo = np.max(proba_subgrupo)\n",
    "\n",
    "   \n",
    "    threshold = 0.2 \n",
    "\n",
    "    \n",
    "    grupo = le_grupo.inverse_transform(pred_grupo)[0]\n",
    "    if max_proba_subgrupo >= threshold:\n",
    "        subgrupo = le_subgrupo.inverse_transform(pred_subgrupo)[0]\n",
    "    else:\n",
    "        subgrupo = 'CATEGORIA NAO EXISTENTE'\n",
    "    return [[descricao_item_original, grupo, subgrupo]]\n",
    "\n",
    "\n",
    "descricao_exemplo = \"DOCE DE COCO CORTE 700G CX 15 UN - SWEET VALLEY\"\n",
    "print(\"\\nPredição para a descrição do item:\")\n",
    "resultado = predizer_grupo_subgrupo(descricao_exemplo)\n",
    "print(resultado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CARNE MOIDA CONGELADA CORDEIRO 700 G', 'OVINOS', 'CATEGORIA NAO EXISTENTE']]\n"
     ]
    }
   ],
   "source": [
    "descricao_exemplo = \"CARNE MOIDA CONGELADA CORDEIRO 700 G\"\n",
    "print(predizer_grupo_subgrupo(descricao_exemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIUDOS - FIGADO DE CORDEIRO CONG.\n",
    "CARNE MOIDA CONGELADA CORDEIRO 700 G\n",
    "DOCE DE COCO CORTE 700G CX 15 UN - SWEET VALLEY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
